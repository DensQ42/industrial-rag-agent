{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d1b0a2",
   "metadata": {},
   "source": [
    "### Clear memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d1d5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec1645",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import torch\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee342e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b0d17",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Load chunks, prepared in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f98862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>page_num</th>\n",
       "      <th>char_count</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>User Guide AWS Toolkit for Microsoft Azure Dev...</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AWS Toolkit for Microsoft Azure DevOps User Gu...</td>\n",
       "      <td>2</td>\n",
       "      <td>422</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>s likely to cause confusion among customers, o...</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>322</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id                                               text  page_num  \\\n",
       "0         0  User Guide AWS Toolkit for Microsoft Azure Dev...         1   \n",
       "1         1  AWS Toolkit for Microsoft Azure DevOps User Gu...         2   \n",
       "2         2  s likely to cause confusion among customers, o...         2   \n",
       "\n",
       "   char_count  start_char  end_char  \n",
       "0         134           0       134  \n",
       "1         422           0       422  \n",
       "2         260         322       822  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = pd.read_json('../data/processed/chunks.json', orient='records')\n",
    "\n",
    "chunks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2295b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 569\n"
     ]
    }
   ],
   "source": [
    "print('Number of chunks:', chunks.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeade647",
   "metadata": {},
   "source": [
    "# Embeddings Creation\n",
    "Embeddings creation is different with LangChain. We need special wrapper that will be used by LangChain when it is needed (no need to explicitly manually create an embedding for each chunk). Here the same sentence transformer `all-MiniLM-L6-v2` model is used that comes within HuggingFace LangChain package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d312e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'normalize_embeddings': True, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c2bec",
   "metadata": {},
   "source": [
    "Test the function with a text sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501b4962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "test_text = 'What is AWS?'\n",
    "test_embedding = embedding_function.embed_query(test_text)\n",
    "\n",
    "print('Embedding dimension:', len(test_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fa7ed",
   "metadata": {},
   "source": [
    "# Vector Database Setup\n",
    "\n",
    "### Convert Chunks to Documents\n",
    "\n",
    "LangChain requires data in special `Document` format, so, let's turn each chunk into document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086a6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in chunks.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=row['text'],\n",
    "        metadata={\n",
    "            'chunk_id': int(row['chunk_id']),\n",
    "            'page_num': int(row['page_num']),\n",
    "            'char_count': int(row['char_count']),\n",
    "            'start_char': int(row['start_char']),\n",
    "            'end_char': int(row['end_char']),\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e9574",
   "metadata": {},
   "source": [
    "Look at the first document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a179462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'chunk_id': 0, 'page_num': 1, 'char_count': 134, 'start_char': 0, 'end_char': 134}, page_content='User Guide AWS Toolkit for Microsoft Azure DevOps Copyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838d578",
   "metadata": {},
   "source": [
    "### Delete Old Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae37079",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    client = chromadb.PersistentClient(path='../data/chromadb')\n",
    "    client.delete_collection('aws_docs_langchain')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2396cc8",
   "metadata": {},
   "source": [
    "### Create Vector Store \n",
    "Create a Vector Store using LangChain. LangChain will automatically embed all documents using provided embedding function and put them into ChromaDB collection. Also, we set up a cosine similarity as a search metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a8a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the collection: aws_docs_langchain\n",
      "Number of documents in collection: 569\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_function,\n",
    "    collection_name='aws_docs_langchain',\n",
    "    persist_directory='../data/chromadb',\n",
    "    collection_metadata={'hnsw:space': 'cosine'},\n",
    ")\n",
    "\n",
    "print('Name of the collection:', vectorstore._collection.name)\n",
    "print('Number of documents in collection:', vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039b1bb",
   "metadata": {},
   "source": [
    "# Sematic Search \n",
    "\n",
    "There is no need to implement semantic search with LangChain, but we can test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3fd144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: If I do not have an AWS account, what do I do?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Rank: 1 | Similarity: 0.699 | Page: 10 | Chunk ID: 77\n",
      "WS account 1. Open https://portal.aws.amazon.com/billing/signup. 2. Follow the online instructions. Part of the sign-up procedure involves receiving a phone call or text message and entering a veriﬁcation code on the phone keypad. When you sign up for an AWS account, an AWS account root user is created. The root user has access to all AWS services and resources in the account. As a security best practice, assign administrative access to a user, and use only the root user to perform tasks that re\n",
      "\n",
      "Rank: 2 | Similarity: 0.639 | Page: 109 | Chunk ID: 77\n",
      "WS, see Troubleshooting AWS identity and access or the user guide of the AWS service you are using. Service administrator – If you're in charge of AWS resources at your company, you probably have full access to AWS. It's your job to determine which AWS features and resources your service users should access. You must then submit requests to your IAM administrator to change the permissions of your service users. Review the information on this page to understand the basic concepts of IAM.\n",
      "\n",
      "Rank: 3 | Similarity: 0.633 | Page: 109 | Chunk ID: 77\n",
      "your job, then your administrator provides you with the credentials and permissions that you need. As you use more AWS features to do your work, you might need additional permissions. Understanding how access is managed can help you request the right permissions from your administrator. If you cannot access a feature in AWS, see Troubleshooting AWS identity and access or the user guide of the AWS service you are using.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = 'If I do not have an AWS account, what do I do?'\n",
    "\n",
    "search_results = vectorstore.similarity_search_with_score(query=test_query, k=3)\n",
    "\n",
    "print('Query:', test_query)\n",
    "print('-' * 100)\n",
    "\n",
    "for i,s in enumerate(search_results, 1):\n",
    "    print(f'Rank: {i} | Similarity: {1-s[1]:.3} | Page: {s[0].metadata['page_num']} | Chunk ID: {search_results[0][0].metadata['chunk_id']}')\n",
    "    print(s[0].page_content, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0610b",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "LangChain uses `PromptTemplate` to define reusable prompt structures. \n",
    "\n",
    "### Create Custom Prompt Template\n",
    "Same prompt template is used here as in previous notebook. Input variables must be put into figure brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f23e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"You are an expert at answering questions about Amazon Web Services documentation.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Read all context chunks from documentation carefully\n",
    "2. Identify which chunks contain relevant information\n",
    "3. Synthesize a clear answer using ONLY the provided context\n",
    "4. Do NOT use your general knowledge and do not make assumptions\n",
    "5. Cite page numbers for each piece of information\n",
    "6. Explicitly state if the answer is not in the provided context\n",
    "7. Write in PLAIN TEXT without any formatting (no bold, no italics, no markdown syntax like ** or __)\n",
    "8. You may use line breaks and simple numbering/bullet points for clarity\n",
    "\n",
    "CONTEXT CHUNKS FROM DOCUMENTATION:\n",
    "{context}\n",
    "\n",
    "USER QUESTION:\n",
    "{query}\n",
    "\n",
    "Think step-by-step, then provide your final ANSWER only without steps.\n",
    "\n",
    "ANSWER:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3a2f8",
   "metadata": {},
   "source": [
    "Use LangChain Prompt Template. Define input variable names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047eb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['context', 'query'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a5858",
   "metadata": {},
   "source": [
    "### Test the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5545e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at answering questions about Amazon Web Services documentation.\n",
      "\n",
      "INSTRUCTIONS:\n",
      "1. Read all context chunks from documentation carefully\n",
      "2. Identify which chunks contain relevant information\n",
      "3. Synthesize a clear answer using ONLY the provided context\n",
      "4. Do NOT use your general knowledge and do not make assumptions\n",
      "5. Cite page numbers for each piece of information\n",
      "6. Explicitly state if the answer is not in the provided context\n",
      "7. Write in PLAIN TEXT without any formatting (no bold, no italics, no markdown syntax like ** or __)\n",
      "8. You may use line breaks and simple numbering/bullet points for clarity\n",
      "\n",
      "CONTEXT CHUNKS FROM DOCUMENTATION:\n",
      "If you do not have an AWS account, go to AWS website and create it\n",
      "\n",
      "USER QUESTION:\n",
      "If I do not have an AWS account, what do I do?\n",
      "\n",
      "Think step-by-step, then provide your final ANSWER only without steps.\n",
      "\n",
      "ANSWER:\n"
     ]
    }
   ],
   "source": [
    "sample_question = 'If I do not have an AWS account, what do I do?'\n",
    "sample_context = 'If you do not have an AWS account, go to AWS website and create it'\n",
    "\n",
    "formatted_prompt = PROMPT.format(\n",
    "    context=sample_context,\n",
    "    query=sample_question,\n",
    ")\n",
    "\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be5095",
   "metadata": {},
   "source": [
    "# RAG Pipeline with LangChain\n",
    "\n",
    "LangChain automates the entire RAG process by chaining components together. In this section there are three main elements:\n",
    "1. Retriever\n",
    "2. Prompt\n",
    "3. LLM\n",
    "\n",
    "### Setup LLM\n",
    "\n",
    "Use the same LLM as in previous notebook. Initialize Claude API client through LangChain wrapper. Here we restrict model temperature to 0.3 to get more certain answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d9d2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "LLM = ChatAnthropic(\n",
    "    model='claude-haiku-4-5-20251001',\n",
    "    temperature=0.3,\n",
    "    max_tokens=500,\n",
    "    anthropic_api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82932a",
   "metadata": {},
   "source": [
    "### Create Retriever\n",
    "\n",
    "Retriever is a LangChain interface for vectorstore that will be used in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a475c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={'k': 5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218c4eb",
   "metadata": {},
   "source": [
    "### Document Formatting\n",
    "Retriever returns the *k* number of documents. They have to be inserted into Prompt. Hence, they must be formatted and concatenated together as plain text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "258be047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_retrieved_docs(docs):\n",
    "    \"\"\"\n",
    "    Formats and concatenates the list of documents.\n",
    "    Returns formatted string.\n",
    "    \"\"\"\n",
    "    context = []\n",
    "    for idx, doc in enumerate(docs, 1):\n",
    "        context.append(f\"[Context chunk {idx} - Page {doc.metadata['page_num']}]\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ff44e",
   "metadata": {},
   "source": [
    "### Build RAG Chain\n",
    "\n",
    "Build RAG chain with LangChain. \n",
    "\n",
    "The first component uses parallel processing, because the Prompt expects both the context (output of the retriever) and the user query (input of the retriever). The query: \n",
    "\n",
    "The second component is the Prompt Template that was defined above. \n",
    "\n",
    "The third component is the LLM that generates responses, it was also defined above. \n",
    "\n",
    "In the end we use `StrOutputParser` that returns only LLM generated text response without metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a114879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_step = RunnableParallel(\n",
    "    {\n",
    "        'context': retriever | format_retrieved_docs,\n",
    "        'query': RunnablePassthrough(),\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = (retriever_step | PROMPT | LLM | StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d8626",
   "metadata": {},
   "source": [
    "### Test the Pipeline\n",
    "Test the pipeline with relevant question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14fff7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documentation, to create an AWS account if you do not have one:\n",
      "\n",
      "1. Open https://portal.aws.amazon.com/billing/signup\n",
      "2. Follow the online instructions\n",
      "3. As part of the sign-up procedure, you will receive a phone call or text message and need to enter a verification code on the phone keypad\n",
      "\n",
      "When you complete the sign-up process, an AWS account root user will be created, which has access to all AWS services and resources in the account.\n",
      "\n",
      "(Page 10)\n"
     ]
    }
   ],
   "source": [
    "query = 'If I do not have an AWS account, what do I do?'\n",
    "\n",
    "result = chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e4203",
   "metadata": {},
   "source": [
    "Test the pipeline with irrelevant question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I make a tasty pizza?'\n",
    "\n",
    "result = chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2bfe1",
   "metadata": {},
   "source": [
    "**Observation:** the model provides correct answer for relevant question and do not hallucinate after irrelevant question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4381f9",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we built the complete RAG pipeline using LangChain with the same quality results as manual approach. The same steps were created: \n",
    "- embedding wrapper function for chunks \n",
    "- database to store embeddings and chunks using `Document` chunk structure\n",
    "- semantic search using cosine similarity \n",
    "- clear and well-structured prompt template for LLMs\n",
    "- complete manual RAG pipeline by chaining components using LCEL (LangChain Expression Language)\n",
    "\n",
    "## Comparison of Approaches\n",
    "\n",
    "| Aspect         | Manual (NB2)          | LangChain (NB3)   |\n",
    "|----------------|-----------------------|-------------------|\n",
    "| Code Length    | ~150 lines            | ~50 lines         |\n",
    "| Flexibility    | Full control          | Less control      |\n",
    "| Debugging      | Easy to trace         | Black box         |\n",
    "| Learning Curve | Understand RAG deeply | Faster to start   |\n",
    "| Production     | Custom solutions      | Standard patterns |\n",
    "| Maintenance    | More effort           | Framework updates |\n",
    "| Best use case  | Research and learning | Fast prototyping  |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
